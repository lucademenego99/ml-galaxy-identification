{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroductionToMachineLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MOcu7yFWWlrr",
        "U4647ZxtXN6m",
        "yQvtvKJxXov8",
        "momgHR1_X9FP",
        "NQdf3BreYEdw",
        "B0gcAUC8YRb1",
        "8B3LPndzYX_L",
        "wsFFvIILYcWa",
        "zLz_SeH7b_ww",
        "BimZk_V1hFqY",
        "RpxXHwm9iwyL",
        "s5jkwXaki4sJ",
        "VvBtLo-ohuCE",
        "m7Wy6xprhyVl",
        "0uJFYzjmiD0u",
        "25qOCOqXiHgF",
        "JCUMoKuiiMLZ",
        "pXRxoIBmiRVe",
        "NA2_fJu0iX02",
        "uGeXtEKYZB6U",
        "MuwwRcvXj-Zu",
        "PadHtpeWjR0z",
        "JhgxliQ8jZL9",
        "ZXJMiFYLjdN0",
        "OtpxeNdmjhp0",
        "BNQ8uLnAjls2",
        "8rTyqpTMjoRg",
        "D_iCTSsZjs6S",
        "waXLU-ZejwKF",
        "Jxf9HFgtXT_L",
        "oZo3ySEOXepT",
        "xdLune6SXlz3",
        "CGb7iba0XqCS",
        "WbaVSQ5TXs9Q",
        "AwsN-PJeXv3J"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucademenego99/ml-galaxy-identification/blob/main/MachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "The objective of the project was to develop an algorithm able to identify, given an RGB image of a galaxy as input, the morphological class it belongs to. In details, we had 10 possible classes: disturbed, merging, round smooth, in-between round smooth, cigar round smooth, barred spiral, unbarred tight spiral, unbarred loose spiral, edge-on with bulge and edge-on without bulge. The dataset provided consisted of 17.736 images of size 256 ×256, divided in\n",
        "train set (12.415 labelled examples) and test set (5.321 non-labelled examples). However, 20% of the training set hasbeen used as validation set, and below accuracies were calculated based on it."
      ],
      "metadata": {
        "id": "sFagH5BfZqLn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOcu7yFWWlrr"
      },
      "source": [
        "# Initialization\n",
        "- Install needed packages\n",
        "- Define useful global variables\n",
        "- Get the device we will use (CPU vs GPU)\n",
        "- Define a ClassificationMetrics class to track the accuracy of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfpv0r0nWiCG",
        "outputId": "cbfa77e4-e81d-4a2d-eb93-65394390d92e"
      },
      "source": [
        "# Install pytorch-ligthning-bolts for LinearWarmupCosineAnnealingLR scheduler\n",
        "!pip install pytorch-lightning-bolts\n",
        "\n",
        "# Enable tensorboard in the notebook\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Device to use\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", DEVICE)\n",
        "\n",
        "# Labels to index and vice versa\n",
        "LABELS_TO_IDX = {\n",
        "  \"Disturbed\": 0, \n",
        "  \"Merging\": 1, \n",
        "  \"Round Smooth\": 2, \n",
        "  \"In-between Round Smooth\": 3, \n",
        "  \"Cigar Shaped Smooth\": 4, \n",
        "  \"Barred Spiral\": 5, \n",
        "  \"Unbarred Tight Spiral\": 6, \n",
        "  \"Unbarred Loose Spiral\": 7, \n",
        "  \"Edge-on without Bulge\": 8, \n",
        "  \"Edge-on with Bulge\": 9\n",
        "}\n",
        "IDX_TO_LABELS = {\n",
        "  0: \"Disturbed\",\n",
        "  1: \"Merging\", \n",
        "  2: \"Round Smooth\", \n",
        "  3: \"In-between Round Smooth\", \n",
        "  4: \"Cigar Shaped Smooth\", \n",
        "  5: \"Barred Spiral\", \n",
        "  6: \"Unbarred Tight Spiral\", \n",
        "  7: \"Unbarred Loose Spiral\", \n",
        "  8: \"Edge-on without Bulge\", \n",
        "  9: \"Edge-on with Bulge\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4647ZxtXN6m"
      },
      "source": [
        "## Performance Evaluation\n",
        "\n",
        "Since we will train and evaluate the neural network by breaking the dataset into mini-batches, we implement a class to track:\n",
        "- global accuracy (Acc); \n",
        "- class-averaged accuracy (mAcc);\n",
        "- class-averaged Intersection over Union (mIoU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfepL7JTXZ2Q"
      },
      "source": [
        "class ClassificationMetrics:\n",
        "\n",
        "  # Constructor takes the number of classes\n",
        "  def __init__(self, num_classes=10):\n",
        "    self.num_classes = num_classes\n",
        "    # Initialize a confusion matrix\n",
        "    self.C = torch.zeros(num_classes, num_classes)\n",
        "    self.C = self.C.to(DEVICE)\n",
        "\n",
        "  # Update the confusion matrix with the new scores\n",
        "  def add(self, yp, yt):\n",
        "    self.C = self.C.to(DEVICE)\n",
        "    # yp: 1D tensor with predictions\n",
        "    # yt: 1D tensor with ground-truth targets\n",
        "    with torch.no_grad(): # We require no computation graph\n",
        "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
        "\n",
        "  def clear(self):\n",
        "    # We set the confusion matrix to zero\n",
        "    self.C.zero_()\n",
        "\n",
        "  # Computes the global accuracy\n",
        "  def acc(self):\n",
        "    return self.C.diag().sum().item()/self.C.sum()\n",
        "\n",
        "  # Computes the class-averaged accuracy\n",
        "  def mAcc(self):\n",
        "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
        "\n",
        "  # Computers the class-averaged Intersection over Union\n",
        "  def mIoU(self):\n",
        "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
        "\n",
        "  # Returns the confusion matrix\n",
        "  def confusion_matrix(self):\n",
        "    return self.C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQvtvKJxXov8"
      },
      "source": [
        "# Download the dataset from Google Drive\n",
        "\n",
        "Run this piece of code only if the dataset is not already downloaded in the notebook and unzipped.\n",
        "\n",
        "**Note**: use the university account in order to get access to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQDPEQXrXsLR",
        "outputId": "bc0b7650-6c6b-483f-8cef-8a03b2eac9fe"
      },
      "source": [
        "from google.colab import drive\n",
        "# Mount my drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Untar the dataset\n",
        "!tar -zxf drive/MyDrive/dataset.tar.gz\n",
        "\n",
        "# Print number of train and test examples\n",
        "!echo \"TEST DATA: \"; find dataset/test -type f | wc -l\n",
        "!echo\n",
        "!echo \"TRAIN DATA: \"; find dataset/train -type f | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "TEST DATA: \n",
            "5321\n",
            "\n",
            "TRAIN DATA: \n",
            "12415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "momgHR1_X9FP"
      },
      "source": [
        "# K-NN, Random Forests and SVM\n",
        "\n",
        "We are trying different methods for the extraction of features. In particular:\n",
        "- **Resized images**\n",
        "- **Color histogram**\n",
        "- **Pre-trained torchvision models** (ResNet18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQdf3BreYEdw"
      },
      "source": [
        "## With resized images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD3IkPl1YGHx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# Transformation we will use\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(150),\n",
        "    transforms.Resize((30, 30)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Get images paths\n",
        "trainImagePaths = list(paths.list_images(\"dataset/train\"))\n",
        "\n",
        "# Prepare some arrays that will store our features and labels\n",
        "X, y = [], []\n",
        "for imagePath in tqdm(trainImagePaths):\n",
        "  image = Image.open(imagePath)\n",
        "  image = transform(image)\n",
        "  image = torch.unsqueeze(image, 0)\n",
        "  X.append(image.cpu().detach().numpy().reshape(-1))\n",
        "  y.append(imagePath.split(\"/\")[2])\n",
        "\n",
        "# Split in train data and test data\n",
        "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0gcAUC8YRb1"
      },
      "source": [
        "### K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bs4fgo4YShW",
        "outputId": "258343aa-67f6-4784-d76b-8b4786a54d4d"
      },
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "print(\"K-NN test with resized images\")\n",
        "knn_model = neighbors.KNeighborsClassifier(n_jobs=-1, weights='distance')\n",
        "\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "res = knn_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "Score: 50.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B3LPndzYX_L"
      },
      "source": [
        "### Random forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjHliYWJYZgG",
        "outputId": "19b6d885-029e-4cb5-babb-f4532cbee86d"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "print(\"Random Forests test with resized images\")\n",
        "rf_model = ensemble.RandomForestClassifier()\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "res = rf_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forests test with resized images\n",
            "Score: 59.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsFFvIILYcWa"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU_J93jcYdLN",
        "outputId": "0fa22003-c443-4828-aecc-a36b0ed8bf8e"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "print(\"SVM test with resized images\")\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "res = svm_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM test with resized images\n",
            "Score: 54.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLz_SeH7b_ww"
      },
      "source": [
        "## With Color Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyOrmXPrcUn_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.CenterCrop((224, 224)),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Get images paths\n",
        "trainImagePaths = list(paths.list_images(\"dataset/train\"))\n",
        "\n",
        "# Prepare some arrays that will store our features and labels\n",
        "X, y = [], []\n",
        "for imagePath in tqdm(trainImagePaths):\n",
        "  alg = cv2.KAZE_create()\n",
        "  image = Image.open(imagePath)\n",
        "  image = transform(image)\n",
        "  color_histogram = torch.histc(image, bins=256)\n",
        "  X.append(color_histogram.cpu().detach().numpy().reshape(-1))\n",
        "  y.append(imagePath.split(\"/\")[2])\n",
        "\n",
        "# Split in train data and test data\n",
        "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BimZk_V1hFqY"
      },
      "source": [
        "### K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8p9fP-9hGme",
        "outputId": "a1713987-5ccc-47c6-960b-8c9003f0c954"
      },
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "print(\"K-NN test with color histogram\")\n",
        "knn_model = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
        "\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "res = knn_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-NN test with color histogram\n",
            "Score: 23.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpxXHwm9iwyL"
      },
      "source": [
        "### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1hqF7lYiyJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d44e214-88af-4c3e-fa46-639681a758f6"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "print(\"Random Forests with color histogram\")\n",
        "rf_model = ensemble.RandomForestClassifier()\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "res = rf_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forests with color histogram\n",
            "Score: 34.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5jkwXaki4sJ"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu96XQEmi5i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c044b6a2-6397-499b-c5e4-d79ceffd8521"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "print(\"SVM with color histogram\")\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "res = svm_model.score(X_test, y_test)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM with color histogram\n",
            "Score: 24.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvBtLo-ohuCE"
      },
      "source": [
        "## With pre-trained model as feature extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Wy6xprhyVl"
      },
      "source": [
        "### Create datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glGx74yrhxBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e9720e-cf4e-46bf-cb78-c611f12de4d0"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from imutils import paths\n",
        "import pandas as pn\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# split_by_percentage splits the examples given a certain percentage, shuffling all_examples\n",
        "def split_by_percentage(all_examples, percentage):\n",
        "    how_many_examples_first_part = int(round(percentage*len(all_examples)))\n",
        "    shuffled = all_examples[:]\n",
        "    random.shuffle(shuffled)\n",
        "    return shuffled[how_many_examples_first_part:], shuffled[:how_many_examples_first_part]\n",
        "\n",
        "# Let's define the batch size for our neural network\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Transforms\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "# GalaxyDataset implements a torch Dataset, defining the __init__, the __len__ and the __getitem__ functions\n",
        "class GalaxyDataset(Dataset):\n",
        "    # Put all input images inside a pandas.DataFrame, set the transformation if given\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.paths = pn.DataFrame([[i, LABELS_TO_IDX[i.split(\"/\")[2]]] for i in images])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    # Open the images only in the __getitem__, so that we can have all their features one batch at a time\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Get the images names from self.paths\n",
        "        img_name = self.paths.iloc[idx, 0]\n",
        "        # Open the images and get their labels\n",
        "        image = Image.open(img_name)\n",
        "        label = self.paths.iloc[idx, 1]\n",
        "        \n",
        "        # Transform the image if a transformation has been provided during the __init__\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Get all images paths\n",
        "all_labelled_examples = list(paths.list_images(\"dataset/train\"))\n",
        "# Split the examples, so that we can have 80% for training and 20% for validation\n",
        "train_examples, test_examples = split_by_percentage(all_labelled_examples, 0.2)\n",
        "print(f\"Number of train examples: {len(train_examples)}, number of test examples: {len(test_examples)}\")\n",
        "\n",
        "# Create a dataset and a dataloader for train examples\n",
        "galaxy_train_dataset = GalaxyDataset(images=train_examples, transform=transform)\n",
        "galaxy_train_dataloader = torch.utils.data.DataLoader(galaxy_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# Create a dataset and a dataloader for test examples\n",
        "galaxy_test_dataset = GalaxyDataset(images=test_examples, transform=transform)\n",
        "galaxy_test_dataloader = torch.utils.data.DataLoader(galaxy_test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train examples: 9932, number of test examples: 2483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uJFYzjmiD0u"
      },
      "source": [
        "### Show data info, with complete example\n",
        "\n",
        "We are showing:\n",
        "- Batch features shape\n",
        "- Batch labels shape\n",
        "- A sample galaxy with its corresponding label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEdUbZrQiEe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "43aa7cd4-e5e0-4c0d-9667-12f56e67b231"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Get a batch of features and labels\n",
        "train_features, train_labels = next(iter(galaxy_train_dataloader))\n",
        "\n",
        "# Print the shape of the data\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "# Permute the image dimension to make plt understand it\n",
        "img = train_features[0].permute(1, 2, 0).squeeze()\n",
        "\n",
        "# Show a sample image with its corresponding label\n",
        "label = train_labels[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(f\"Label: {label} - {IDX_TO_LABELS[label.item()]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 3, 224, 224])\n",
            "Labels batch shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label: 5 - Barred Spiral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25qOCOqXiHgF"
      },
      "source": [
        "### Define pre-trained ResNet18 model and extract features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q738LyeAiKwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ada3d0-d534-42cf-de5c-e90216322593"
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# extract_features extract some features given a pre-trained model\n",
        "def extract_features(model, dataloader, return_labels=False):\n",
        "  res_features, res_ys = [], []\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader):\n",
        "        # Get images and labels from the batch and put them into the DEVICE\n",
        "        images, ys = batch\n",
        "        images = images.to(DEVICE)\n",
        "        if return_labels:\n",
        "          ys = ys.to(DEVICE)\n",
        "\n",
        "        # Get the output from the neural network\n",
        "        outputs = model(images)\n",
        "        features_to_append = []\n",
        "        ys_to_append = []\n",
        "\n",
        "        for i in range(len(outputs)):\n",
        "          features_to_append.append(outputs[i].cpu().detach().numpy().reshape(-1))\n",
        "        if return_labels:\n",
        "          for i in range(len(ys)):\n",
        "            ys_to_append.append(ys[i].item())\n",
        "        else:\n",
        "          for i in range(len(ys)):\n",
        "            ys_to_append.append(ys[i])\n",
        "\n",
        "        res_features.extend(features_to_append)\n",
        "        res_ys.extend(ys_to_append)\n",
        "  return res_features, res_ys\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "  \n",
        "# Setup model\n",
        "pretrained_model = models.resnet18(pretrained=True)\n",
        "# Remove the last layer setting it to Identity\n",
        "pretrained_model.fc = Identity()\n",
        "\n",
        "# Put the model into our device\n",
        "pretrained_model.to(DEVICE)\n",
        "\n",
        "features, labels = extract_features(pretrained_model, galaxy_train_dataloader, True)\n",
        "test_features, test_labels = extract_features(pretrained_model, galaxy_test_dataloader, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156/156 [00:38<00:00,  4.01it/s]\n",
            "100%|██████████| 39/39 [00:09<00:00,  4.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCUMoKuiiMLZ"
      },
      "source": [
        "### K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jRwJelRiNvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6405534a-ebc6-49aa-dced-9e62330cf1a3"
      },
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "print(\"K-NN with pre-trained model as feature extractor\")\n",
        "knn_model = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
        "\n",
        "knn_model.fit(features, labels)\n",
        "\n",
        "res = knn_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-NN with pre-trained model as feature extractor\n",
            "Score: 34.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXRxoIBmiRVe"
      },
      "source": [
        "### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlcOETS3iS5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9dd084-7e1e-4632-ec57-f2c737003e43"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "print(\"Random Forests with pre-trained model as feature extractor\")\n",
        "rf_model = ensemble.RandomForestClassifier()\n",
        "\n",
        "rf_model.fit(features, labels)\n",
        "\n",
        "res = rf_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forests with pre-trained model as feature extractor\n",
            "Score: 38.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA2_fJu0iX02"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm5VpzmciYo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11774e90-1df1-4c6a-e23a-21d28b5ea935"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "print(\"SVM with pre-trained model as feature extractor\")\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(features, labels)\n",
        "\n",
        "res = svm_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM with pre-trained model as feature extractor\n",
            "Score: 48.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGeXtEKYZB6U"
      },
      "source": [
        "# Neural networks\n",
        "\n",
        "We are using the following NNs:\n",
        "- **ResNet18**\n",
        "- **ResNet50**\n",
        "\n",
        "\n",
        "Some details:\n",
        "- Epochs: 200\n",
        "- Optimizer: **Adam** with initial learning rate set to 0.001\n",
        "- Scheduler: **LinearWarmupCosineAnnealing** with 50 warmup epochs\n",
        "- Loss Function: **CrossEntropyLoss**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuwwRcvXj-Zu"
      },
      "source": [
        "## Define train and test functions + some utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYx0sfMjkEOB"
      },
      "source": [
        "# train trains the input neural network using a given dataloader and a given number of epochs\n",
        "def train(net, epochs, trainDataloader, valDataloader, optimizer, scheduler, tblog=None):\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  metric_tracker = ClassificationMetrics(10)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # Set model to training mode\n",
        "    net.train()\n",
        "    # Clear the metric tracker\n",
        "    metric_tracker.clear()\n",
        "\n",
        "    print(f\"-- EPOCH {epoch+1}/{epochs} -------------------------\\n\")\n",
        "\n",
        "    # Iterate through trainDataloader and train the model\n",
        "    i = 0\n",
        "    for batch in tqdm(trainDataloader):\n",
        "      # Get images and labels from the batch and put them into the DEVICE\n",
        "      images, labels = batch\n",
        "      images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "      # Set gradients to zero before backpropagation\n",
        "      net.zero_grad()\n",
        "\n",
        "      # Get the output from the neural network\n",
        "      outputs = net(images)\n",
        "      outputs.to(DEVICE)\n",
        "\n",
        "      # Calculate the loss function\n",
        "      loss = loss_function(outputs, labels)\n",
        "\n",
        "      # The index of the largest output along the second dimension gives the predicted class label\n",
        "      y = outputs.argmax(-1)\n",
        "      y = y.to(DEVICE)\n",
        "\n",
        "      # Track evaluation metrics\n",
        "      metric_tracker.add(y, labels)\n",
        "\n",
        "      # If a tensorboard summary writer is available we track the loss value\n",
        "      # and the metrics of each iteration\n",
        "      if tblog:\n",
        "        tblog.add_scalar('train/loss', loss.item(), epoch*len(trainDataloader)+i)\n",
        "\n",
        "      # Perform the backward pass to compute gradients\n",
        "      loss.backward()\n",
        "      # Update the parameters\n",
        "      optimizer.step()\n",
        "      i += 1\n",
        "\n",
        "    # Print metrics accumulated over the epoch\n",
        "    print(\"\\tTRAIN | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\".format(\n",
        "        metric_tracker.acc(), metric_tracker.mAcc(), metric_tracker.mIoU()\n",
        "    ))\n",
        "\n",
        "    # Track the metrics in the tensorboard log\n",
        "    if tblog:\n",
        "      tblog.add_scalar('train/acc', metric_tracker.acc(), epoch)\n",
        "      tblog.add_scalar('train/mAcc', metric_tracker.mAcc(), epoch)\n",
        "      tblog.add_scalar('train/mIoU', metric_tracker.mIoU(), epoch)\n",
        "      tblog.add_scalar('train/lr', scheduler.get_last_lr()[0], epoch)\n",
        "    \n",
        "    # Evaluate the current model\n",
        "    validate(net, metric_tracker, valDataloader)\n",
        "\n",
        "    # Print metrics over the validation set\n",
        "    print(\"\\tEVAL  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(\n",
        "        metric_tracker.acc(), \n",
        "        metric_tracker.mAcc(), metric_tracker.mIoU()\n",
        "    ))\n",
        "\n",
        "    # Track the metrics in the tensorboard log\n",
        "    if tblog:\n",
        "      tblog.add_scalar('val/acc', metric_tracker.acc(), epoch)\n",
        "      tblog.add_scalar('val/mAcc', metric_tracker.mAcc(), epoch)\n",
        "      tblog.add_scalar('val/mIoU', metric_tracker.mIoU(), epoch)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "def validate(net, metric_tracker, dataloader):\n",
        "  net.eval()\n",
        "  metric_tracker.clear()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader):\n",
        "      images, labels = batch\n",
        "      images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "      outputs = net(images)\n",
        "      outputs = outputs.to(DEVICE)\n",
        "      y = outputs.argmax(-1)\n",
        "      y = y.to(DEVICE)\n",
        "      metric_tracker.add(y, labels)\n",
        "\n",
        "def test(model, dataloader):\n",
        "  # We create the performance metric tracker\n",
        "  metric_tracker = ClassificationMetrics(10)\n",
        "\n",
        "  # We run the validation code con the test data and track the performance\n",
        "  validate(model,metric_tracker, dataloader)\n",
        "\n",
        "  # Print metrics over the test set\n",
        "  print(\"TEST  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(\n",
        "      metric_tracker.acc(), \n",
        "      metric_tracker.mAcc(), metric_tracker.mIoU()\n",
        "  ))\n",
        "\n",
        "  return metric_tracker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1MemVtWkJOg"
      },
      "source": [
        "def write_results_to_csv(net, dataloader):\n",
        "  # Open tmp csv file with results\n",
        "  csv_file = open(\"results_tmp.csv\", \"w\")\n",
        "  writer = csv.writer(csv_file)\n",
        "\n",
        "  # Get outputs from net\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader):\n",
        "      images, names = batch\n",
        "      images = images.to(DEVICE)\n",
        "\n",
        "      net_out = net(images)\n",
        "      for i in range(len(names)):\n",
        "        writer.writerow([names[i], IDX_TO_LABELS[torch.argmax(net_out[i]).item()]])\n",
        "  csv_file.close()\n",
        "\n",
        "  # Read the created csv\n",
        "  reader = csv.reader(open(\"results_tmp.csv\"), delimiter=\",\")\n",
        "\n",
        "  # Sort the csv into a sorted_list\n",
        "  sorted_list = sorted(reader, key=lambda row: int(row[0]), reverse=False)\n",
        "\n",
        "  # Save the sorted csv in results.csv\n",
        "  sorted_csv = open(\"results.csv\", \"w\")\n",
        "  sorted_writer = csv.writer(sorted_csv)\n",
        "  for entry in sorted_list:\n",
        "    sorted_writer.writerow(entry)\n",
        "  sorted_csv.close()\n",
        "\n",
        "  # Download the csv\n",
        "  files.download('results.csv')\n",
        "\n",
        "def write_sklearn_results_to_csv(model, features, names):\n",
        "  # Open tmp csv file with results\n",
        "  csv_file = open(\"results_tmp.csv\", \"w\")\n",
        "  writer = csv.writer(csv_file)\n",
        "\n",
        "  # Get outputs from model\n",
        "  for i in range(len(features)):\n",
        "    model_out = model.predict(features[i].reshape(1, -1))\n",
        "    writer.writerow([names[i], IDX_TO_LABELS[model_out[0]]])\n",
        "  csv_file.close()\n",
        "\n",
        "  # Read the created csv\n",
        "  reader = csv.reader(open(\"results_tmp.csv\"), delimiter=\",\")\n",
        "\n",
        "  # Sort the csv into a sorted_list\n",
        "  sorted_list = sorted(reader, key=lambda row: int(row[0]), reverse=False)\n",
        "\n",
        "  # Save the sorted csv in results.csv\n",
        "  sorted_csv = open(\"results.csv\", \"w\")\n",
        "  sorted_writer = csv.writer(sorted_csv)\n",
        "  for entry in sorted_list:\n",
        "    sorted_writer.writerow(entry)\n",
        "  sorted_csv.close()\n",
        "\n",
        "  # Download the csv\n",
        "  files.download('results.csv')\n",
        "\n",
        "# split_by_percentage splits the examples given a certain percentage, shuffling all_examples\n",
        "def split_by_percentage(all_examples, percentage):\n",
        "    how_many_examples_first_part = int(round(percentage*len(all_examples)))\n",
        "    shuffled = all_examples[:]\n",
        "    random.shuffle(shuffled)\n",
        "    return shuffled[how_many_examples_first_part:], shuffled[:how_many_examples_first_part]\n",
        "\n",
        "# extract_features extract some features given a pre-trained model\n",
        "def extract_features(model, dataloader, return_labels=False):\n",
        "  res_features, res_ys = [], []\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader):\n",
        "        # Get images and labels from the batch and put them into the DEVICE\n",
        "        images, ys = batch\n",
        "        images = images.to(DEVICE)\n",
        "        if return_labels:\n",
        "          ys = ys.to(DEVICE)\n",
        "\n",
        "        # Get the output from the neural network\n",
        "        outputs = model(images)\n",
        "        features_to_append = []\n",
        "        ys_to_append = []\n",
        "\n",
        "        for i in range(len(outputs)):\n",
        "          features_to_append.append(outputs[i].cpu().detach().numpy().reshape(-1))\n",
        "        if return_labels:\n",
        "          for i in range(len(ys)):\n",
        "            ys_to_append.append(ys[i].item())\n",
        "        else:\n",
        "          for i in range(len(ys)):\n",
        "            ys_to_append.append(ys[i])\n",
        "\n",
        "        res_features.extend(features_to_append)\n",
        "        res_ys.extend(ys_to_append)\n",
        "  return res_features, res_ys\n",
        "\n",
        "def run_experiment(name, model, epochs, trainDataloader, valDataloader):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "  scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs=round(epochs/4), max_epochs=epochs)\n",
        "  # We create the tensorboard logger\n",
        "  tblog=tb.SummaryWriter(f\"exps/{name}\")\n",
        "  print(f\"TRAINING: exps/{name}\")\n",
        "  # We train our model\n",
        "  train(model, epochs, trainDataloader, valDataloader, optimizer, scheduler, tblog=tblog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PadHtpeWjR0z"
      },
      "source": [
        "## Define a custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMaxuJmVjVPk"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pn\n",
        "\n",
        "# GalaxyDataset implements a torch Dataset, defining the __init__, the __len__ and the __getitem__ functions\n",
        "class GalaxyDataset(Dataset):\n",
        "    # Put all input images inside a pandas.DataFrame, set the transformation if given\n",
        "    def __init__(self, images, transform=None, is_result=False):\n",
        "        self.is_result = is_result\n",
        "        if is_result:\n",
        "          self.paths = pn.DataFrame([[i, i.split(\"/\")[2].split(\".\")[0]] for i in images])\n",
        "        else:\n",
        "          self.paths = pn.DataFrame([[i, LABELS_TO_IDX[i.split(\"/\")[2]]] for i in images])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    # Open the images only in the __getitem__, so that we can have all their features one batch at a time\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        # Get the images names from self.paths\n",
        "        img_name = self.paths.iloc[idx, 0]\n",
        "        # Open the images and get their labels\n",
        "        image = Image.open(img_name)\n",
        "        label = self.paths.iloc[idx, 1]\n",
        "        # Apply a transformation if specified\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        # Return a labelled example\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhgxliQ8jZL9"
      },
      "source": [
        "## Split train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYymyCI5jbbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58775088-a830-42ea-b671-ec933bdd4213"
      },
      "source": [
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "all_examples = []\n",
        "all_train_examples = []\n",
        "all_val_examples = []\n",
        "classes_counts = []\n",
        "\n",
        "# Base path for our images\n",
        "base_path = os.path.join(\"dataset\", \"train\")\n",
        "\n",
        "# All possible classes\n",
        "classes = list(os.listdir(base_path))\n",
        "\n",
        "# Get all examples divided by class\n",
        "for galaxy_class in classes:\n",
        "  class_path = os.path.join(base_path, galaxy_class)\n",
        "  print(f\"Found class path: {class_path}\")\n",
        "  to_append = list(paths.list_images(class_path))\n",
        "  classes_counts.append(len(to_append))\n",
        "  all_examples.append(to_append)\n",
        "\n",
        "# Split validation and training data\n",
        "for class_examples in all_examples:\n",
        "  if len(class_examples) > 500:\n",
        "    all_val_examples.append(class_examples[-round(len(class_examples)/100*20):])\n",
        "    all_train_examples.append(class_examples[:round(len(class_examples)/100*80)])\n",
        "  else:\n",
        "    all_val_examples.append(class_examples[-round(len(class_examples)/100*10):])\n",
        "    all_train_examples.append(class_examples[:round(len(class_examples)/100*90)])\n",
        "\n",
        "# Get all images paths\n",
        "all_train_examples = np.concatenate(all_train_examples, axis=0)\n",
        "all_val_examples = np.concatenate(all_val_examples, axis=0)\n",
        "\n",
        "print(f\"\\nNumber of train examples: {len(all_train_examples)}\")\n",
        "print(f\"Number of validation examples: {len(all_val_examples)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found class path: dataset/train/Unbarred Loose Spiral\n",
            "Found class path: dataset/train/In-between Round Smooth\n",
            "Found class path: dataset/train/Round Smooth\n",
            "Found class path: dataset/train/Barred Spiral\n",
            "Found class path: dataset/train/Merging\n",
            "Found class path: dataset/train/Edge-on with Bulge\n",
            "Found class path: dataset/train/Unbarred Tight Spiral\n",
            "Found class path: dataset/train/Edge-on without Bulge\n",
            "Found class path: dataset/train/Cigar Shaped Smooth\n",
            "Found class path: dataset/train/Disturbed\n",
            "\n",
            "Number of train examples: 9957\n",
            "Number of validation examples: 2458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXJMiFYLjdN0"
      },
      "source": [
        "## Create datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6obal8rcjfvS"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Let's define the batch size for our neural network\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Transforms\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "transform = {\n",
        "    'train': transforms.RandomChoice([\n",
        "      transforms.Compose([\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        transforms.RandomRotation(degrees=90),\n",
        "        transforms.RandomAffine(degrees=180),\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.2),\n",
        "        transforms.RandomHorizontalFlip(p=0.4),\n",
        "        transforms.RandomVerticalFlip(p=0.4),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "      ]),\n",
        "      transforms.Compose([\n",
        "        transforms.CenterCrop((224, 224)),\n",
        "        transforms.RandomRotation(degrees=270),\n",
        "        transforms.RandomAffine(degrees=90),\n",
        "        transforms.RandomPerspective(distortion_scale=0.4, p=0.1),\n",
        "        transforms.RandomHorizontalFlip(p=0.2),\n",
        "        transforms.RandomVerticalFlip(p=0.2),\n",
        "        transforms.GaussianBlur(9),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "      ]),\n",
        "      transforms.Compose([\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        transforms.RandomRotation(degrees=180),\n",
        "        transforms.RandomAffine(degrees=270),\n",
        "        transforms.RandomPerspective(distortion_scale=0.1, p=0.3),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "      ])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "      transforms.CenterCrop((224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std)\n",
        "    ])\n",
        "}\n",
        "\n",
        "galaxy_train_dataset = GalaxyDataset(images=all_train_examples, transform=transform['train'])\n",
        "galaxy_val_dataset = GalaxyDataset(images=all_val_examples, transform=transform['val'])\n",
        "\n",
        "# Define the weights of each class as the inverse of the class counts\n",
        "weights = 1. / torch.tensor(classes_counts, dtype=torch.float)\n",
        "# Get the weight of each sample\n",
        "samples_weights = weights[galaxy_train_dataset.paths.iloc[:, 1]]\n",
        "# Define a sampler based on the weights just defined\n",
        "sampler = torch.utils.data.WeightedRandomSampler(\n",
        "    weights=samples_weights,\n",
        "    num_samples=len(samples_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Train dataloader, with a sampler\n",
        "loader_train = torch.utils.data.DataLoader(galaxy_train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True, drop_last=False)\n",
        "# Validation dataloader, we don't need the sampler\n",
        "loader_val = torch.utils.data.DataLoader(galaxy_val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtpxeNdmjhp0"
      },
      "source": [
        "## Show some info about our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4psUlYCjkFa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "250851d9-4914-4d5f-e9f0-ddedfbc0d645"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Get a batch of features and labels\n",
        "train_features, train_labels = next(iter(loader_train))\n",
        "\n",
        "# Print the shape of the data\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "# Permute the image dimension to make plt understand it\n",
        "img = train_features[0].permute(1, 2, 0).squeeze()\n",
        "\n",
        "# Show a sample image with its corresponding label\n",
        "label = train_labels[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(f\"Label: {label} - {IDX_TO_LABELS[label.item()]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([128, 3, 224, 224])\n",
            "Labels batch shape: torch.Size([128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label: 5 - Barred Spiral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNQ8uLnAjls2"
      },
      "source": [
        "## ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1hg98W0jm_M"
      },
      "source": [
        "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
        "import torch.utils.tensorboard as tb\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"RESNET18\\n\")\n",
        "\n",
        "# Set number of epochs for resnet18\n",
        "EPOCHS = 200\n",
        "\n",
        "print(f\"Working with {DEVICE}\")\n",
        "print(f\"Number of EPOCHS: {EPOCHS}\")\n",
        "\n",
        "print(\"\\nCreating Model...\\n\")\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18.fc = nn.Linear(512, 10) # 10 output classes instead of 1000\n",
        "resnet18.to(DEVICE)\n",
        "\n",
        "run_experiment(\"Resnet18-aug\", resnet18, EPOCHS, loader_train, loader_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rTyqpTMjoRg"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecwfdsCtjpcR"
      },
      "source": [
        "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"RESNET50\\n\")\n",
        "\n",
        "# Set number of epochs for resnet50\n",
        "EPOCHS = 200\n",
        "\n",
        "print(f\"Working with {DEVICE}\")\n",
        "print(f\"Number of EPOCHS: {EPOCHS}\")\n",
        "\n",
        "print(\"\\nCreating Model...\\n\")\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 10) # 10 output classes instead of 1000\n",
        "resnet50.to(DEVICE)\n",
        "\n",
        "run_experiment(\"resnet50-aug\", resnet50, EPOCHS, loader_train, loader_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_iCTSsZjs6S"
      },
      "source": [
        "## Write results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpzDDSR9juGU"
      },
      "source": [
        "all_test_examples = list(paths.list_images(\"dataset/test\"))\n",
        "galaxy_results_dataset = GalaxyDataset(images=all_test_examples, transform=transform['val'], is_result=True)\n",
        "galaxy_results_dataloader = torch.utils.data.DataLoader(galaxy_results_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "write_results_to_csv(resnet18, galaxy_results_dataloader)\n",
        "write_results_to_csv(resnet50, galaxy_results_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waXLU-ZejwKF"
      },
      "source": [
        "## Open Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvZOUHBpjvi3"
      },
      "source": [
        "%tensorboard --logdir exps/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxf9HFgtXT_L"
      },
      "source": [
        "# Extra - K-NN, Random Forests and SVM with our NN as FE\n",
        "\n",
        "After having trained our ResNet18 model, we use it as a feature extractor, and we check the accuracy we get using shallow methods.\n",
        "\n",
        "The accuracies we see below are obtained using a ResNet18 model as feature extractor trained for 100 epochs, with the hyperparameters specified above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZo3ySEOXepT"
      },
      "source": [
        "## Remove the last FC layer from our NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0bD9WJDXdRO",
        "outputId": "13f777b1-7a51-4b8c-fb41-3fc127e769f4"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "# We will use our trained resnet18 model\n",
        "resnet18.fc = Identity()\n",
        "\n",
        "# Extract features\n",
        "features, labels = extract_features(resnet18, loader_train, True)\n",
        "test_features, test_labels = extract_features(resnet18, loader_val, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:43<00:00,  1.81it/s]\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdLune6SXlz3"
      },
      "source": [
        "## K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCvOpk3WXnCh",
        "outputId": "9e1e2e2b-a501-4514-8b85-638642529a51"
      },
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "print(\"KNN\")\n",
        "knn_model = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
        "\n",
        "knn_model.fit(features, labels)\n",
        "\n",
        "res = knn_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100)) # 84%, 10s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "Score: 82.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGb7iba0XqCS"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAWm_KHpXrS8",
        "outputId": "eca380a2-1d3f-40ff-9926-cc7f7e89025f"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "print(\"Random Forests\")\n",
        "rf_model = ensemble.RandomForestClassifier()\n",
        "\n",
        "rf_model.fit(features, labels)\n",
        "\n",
        "res = rf_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100)) # 84%, 30s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forests\n",
            "Score: 84.05%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbaVSQ5TXs9Q"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds99WE6WXtvn",
        "outputId": "1e8016dc-ea6e-4e05-ab3d-d695ce14c692"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "print(\"SVM\")\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(features, labels)\n",
        "\n",
        "res = svm_model.score(test_features, test_labels)\n",
        "print(\"Score: {:.2f}%\".format(res * 100)) # 84%, 15s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM\n",
            "Score: 84.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwsN-PJeXv3J"
      },
      "source": [
        "## Get Confusion Matrix of SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "N23DA1P4Xx0A",
        "outputId": "2099272f-f260-4c5e-fe20-46d91d9868b1"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_confusion_matrix(svm_model, test_features, test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}